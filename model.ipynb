{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "\n",
    "from glob import glob\n",
    "import csv\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lọc danh sách objects để tăng tốc độ xử lí\n",
    "\n",
    "- Chỉ lấy 1 object mỗi frame và chỉ khi object có điểm >= 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chạy một lần thôi, để tạo thư mục objects_filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./objects_filtered', exist_ok=True)\n",
    "objects_paths = glob('./objects\\\\*\\\\*.json')\n",
    "\n",
    "for obj_path in objects_paths:\n",
    "    with open(obj_path, 'r') as r_stream:\n",
    "        keyframe_filename = obj_path.split('\\\\')[-2] + '/' + obj_path.split('\\\\')[-1]\n",
    "        obj = json.load(r_stream)\n",
    "        obj_filtered = {\n",
    "            \"Objects\": [],\n",
    "            \"Scores\": []\n",
    "        }\n",
    "        idx = 0\n",
    "        for score in obj[\"detection_scores\"][:1]:\n",
    "            if float(score) < 0.7:\n",
    "                break\n",
    "            else:\n",
    "                obj_filtered[\"Scores\"].append(score)\n",
    "                obj_filtered[\"Objects\"].append(obj[\"detection_class_entities\"][idx])\n",
    "                idx += 1\n",
    "        os.makedirs('./objects_filtered/' + keyframe_filename.split('/')[0], exist_ok=True)\n",
    "        with open('./objects_filtered/' + keyframe_filename, 'w') as w_stream:\n",
    "            json.dump(obj_filtered, w_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tải model xử lí ngôn ngữ tự nhiên en_core_web_lg từ spacy\n",
    "\n",
    "- Nếu đã tải rồi thì thôi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load nlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP vectors\n",
    "\n",
    "- Đọc và tạo mảng gồm tất cả các CLIP vectors để đưa vào model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo list tên video và tên keyframe để lát đổi chiếu\n",
    "objects_paths = glob('./objects_filtered\\\\*\\\\*.json')\n",
    "\n",
    "keyframe_names = []\n",
    "for path in objects_paths:\n",
    "    vid_frameid = [path.split('\\\\')[-2], path.split('\\\\')[-1].split('.')[0]]\n",
    "    keyframe_names.append(vid_frameid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L01_V001', '0002']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyframe_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199110"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keyframe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_paths = glob('./clip-features-vit-b32\\\\*.npy')\n",
    "clip_embeddings = np.load(clip_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Đọc và tạo numpy array embeddings CLIP\n",
    "for path in clip_paths[1:]:\n",
    "    c_vector = np.load(path)\n",
    "    clip_embeddings = np.append(clip_embeddings, c_vector, axis=0)\n",
    "    #clip_embeddings = np.concatenate(clip_embeddings, c_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeddings = clip_embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03004456,  0.03555298,  0.01282501, ...,  0.05236816,\n",
       "        -0.03994751, -0.01226044],\n",
       "       [ 0.00272942, -0.03497314,  0.01190186, ...,  0.09503174,\n",
       "        -0.01295471,  0.00335312],\n",
       "       [-0.00409698, -0.02764893, -0.0124054 , ...,  0.08166504,\n",
       "         0.00548172,  0.00435638],\n",
       "       ...,\n",
       "       [-0.04769897,  0.0136261 , -0.0019722 , ...,  0.15551758,\n",
       "        -0.06311035, -0.01803589],\n",
       "       [-0.03121948,  0.01737976, -0.02980042, ...,  0.08605957,\n",
       "        -0.02941895, -0.01332855],\n",
       "       [ 0.00219727,  0.00026584, -0.00503922, ...,  0.06530762,\n",
       "         0.00248718, -0.01753235]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202148"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clip_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển numpy array sang tensor của tensorflow\n",
    "# img_emb = tf.convert_to_tensor(clip_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các hàm predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm áp dụng model clip-ViT-B-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tìm bằng CLIP vectors\n",
    "def clip_search(query, img_embs, k=5):\n",
    "    #Initialize model\n",
    "    clip_model = SentenceTransformer('clip-ViT-B-32')\n",
    "    \n",
    "    query_emb = clip_model.encode([query], convert_to_tensor=True, show_progress_bar=False)\n",
    "    \n",
    "    hits = util.semantic_search(query_emb, img_embs, top_k=k)[0]\n",
    "    \n",
    "    results = []\n",
    "    for hit in hits:\n",
    "        result = keyframe_names[hit['corpus_id']]\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm áp dụng objects để tiếp tục lọc\n",
    "\n",
    "- B1: Ta lọc ra các chủ ngữ, đối tượng trong query.\n",
    "\n",
    "- B2: Ta tính điểm cho từng keyframes, nếu frame nào ko có objects thì coi như điểm = 0\n",
    "+ Cách thức tính điểm: **SUM(similarity * confidence)**\n",
    "\n",
    "similarity là điểm tương đồng giữa tên object và tên của từng chủ ngữ, đối tượng, ta tính xong lấy max\n",
    "\n",
    "confidence là điểm confidence của object đó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lọc qua objects\n",
    "def objects_filtering(clip_results, query, nlp_model, k=3):\n",
    "    # Extract subjects + objects from query\n",
    "    query_objs = []\n",
    "    doc = nlp_model(query)\n",
    "    # for word in doc:\n",
    "    #     if word.dep_ == \"nsubj\" or word.dep_ == \"iobj\" or word.dep_ == \"dobj\":\n",
    "    #         query_objs.append(word)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        query_objs.append(chunk)\n",
    "    \n",
    "    #Scoring\n",
    "    scores = []\n",
    "    for kf in clip_results:\n",
    "        obj_path = './objects_filtered/' + kf[0] + '/' + kf[1] + '.json'\n",
    "        with open(obj_path, 'r') as r_stream:\n",
    "            obj = json.load(r_stream)\n",
    "            score = 0\n",
    "            \n",
    "            for object, confidence in zip(obj[\"Objects\"], obj[\"Scores\"]):\n",
    "                sims = []\n",
    "                for query_obj in query_objs:\n",
    "                    sims.append(nlp_model(object).similarity(query_obj))\n",
    "                similarity = max(sims)\n",
    "                score += similarity * float(confidence) #Score is sum of the similarity of the object to the query * confidence score\n",
    "                \n",
    "            if len(obj[\"Objects\"]) == 0: # Remain impartial to frames with no objects ?\n",
    "                score = 0.5\n",
    "        scores.append(score)\n",
    "        \n",
    "    #Get top k frames\n",
    "    top_k = np.argsort(scores)[-k:]\n",
    "    return [clip_results[x] for x in top_k]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lọc concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concepts_filtering(clip_results, query, nlp_model, k=3):\n",
    "    # Extract subjects + objects from query\n",
    "    query_objs = []\n",
    "    doc = nlp_model(query)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        query_objs.append(chunk)\n",
    "    \n",
    "    scores = []\n",
    "    for kf in clip_results:\n",
    "        concept_path = './concepts/' + kf[0] + '/' + kf[1] + '.json'\n",
    "        with open(concept_path, 'r') as r_stream:\n",
    "            concept = json.load(r_stream)\n",
    "            score = 0\n",
    "            sims = []\n",
    "            for query_obj in query_objs:\n",
    "                sims.append(nlp_model(concept).similarity(query_obj))\n",
    "            score = max(sims)\n",
    "        scores.append(score)\n",
    "    \n",
    "    #Get top k frames\n",
    "    top_k = np.argsort(scores)[-k:]\n",
    "    return [clip_results[x] for x in top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm predict cuối\n",
    "\n",
    "- B1: Lọc bằng CLIP vectors\n",
    "\n",
    "- B2: Lọc tiếp bằng objects\n",
    "\n",
    "- B?? ... (có thể cải tiến thêm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query, clip_embeds, nlp_model, k=5):\n",
    "    \n",
    "    clip_results = clip_search(query, clip_embeds, k*3)\n",
    "    \n",
    "    concept_results = concepts_filtering(clip_results, query, nlp_model, k*2)\n",
    "    \n",
    "    objects_results = objects_filtering(concept_results, query, nlp_model, k)\n",
    "    \n",
    "    #Mapping results to actual frame numbers\n",
    "    final_results = []\n",
    "    for result in objects_results:\n",
    "        path = './map-keyframes/' + result[0] + '.csv'\n",
    "        with open(path, 'r') as r_stream:\n",
    "            csvreader = csv.reader(r_stream)\n",
    "            next(csvreader) #Skip columns names\n",
    "            \n",
    "            for row in csvreader:\n",
    "                if int(row[0]) == int(result[1]):\n",
    "                    # final_results.append([result[0], int(row[3]) + np.random.randint(-150,150)])\n",
    "                    final_results.append([result[0], int(row[3]) + np.random.randint(-2,2)])\n",
    "                    break\n",
    "    \n",
    "    #upload to csv file\n",
    "    print(\"Prediction complete! Writing to csv file...\")\n",
    "    os.makedirs('./results', exist_ok=True)\n",
    "    with open('./results/newest_result.csv', 'w', newline='') as w_stream:\n",
    "        csvwriter = csv.writer(w_stream)\n",
    "        csvwriter.writerows(final_results)\n",
    "    print(\"Complete\")\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction complete! Writing to csv file...\n",
      "Complete\n",
      "[['L09_V014', 11763], ['L09_V008', 10019], ['L05_V022', 4626], ['L10_V010', 3777], ['L10_V013', 30168], ['L10_V015', 29365], ['L08_V014', 26287], ['L08_V010', 25295], ['L01_V006', 14188], ['L02_V016', 14189], ['L06_V019', 23554], ['L08_V018', 29513], ['L01_V020', 10623], ['L01_V014', 6587], ['L07_V013', 10283], ['L04_V017', 22488], ['L08_V009', 21151], ['L10_V014', 32577], ['L01_V008', 12596], ['L08_V019', 23093], ['L02_V022', 9069], ['L09_V021', 15627], ['L10_V013', 35050], ['L07_V015', 13189], ['L10_V030', 5634], ['L08_V009', 21236], ['L06_V028', 20217], ['L04_V014', 9948], ['L06_V014', 2427], ['L06_V020', 3801], ['L05_V004', 3502], ['L08_V015', 14239], ['L04_V016', 19232], ['L10_V013', 34921], ['L03_V007', 9089], ['L05_V027', 11067], ['L07_V019', 3027], ['L04_V006', 26949], ['L06_V009', 9372], ['L04_V002', 28156], ['L10_V018', 21661], ['L07_V019', 16528], ['L10_V005', 21401], ['L01_V008', 12439], ['L05_V027', 11586], ['L03_V021', 6690], ['L02_V028', 17617], ['L06_V009', 17340], ['L02_V012', 24924], ['L06_V005', 11299], ['L02_V019', 10567], ['L01_V009', 9807], ['L07_V026', 9028], ['L10_V009', 29593], ['L01_V017', 18989], ['L07_V005', 21661], ['L10_V028', 17649], ['L01_V001', 6962], ['L03_V023', 7351], ['L04_V005', 6262], ['L08_V010', 25543], ['L08_V010', 24916], ['L09_V026', 3712], ['L05_V008', 472], ['L06_V015', 23682], ['L02_V011', 20094], ['L02_V019', 10413], ['L10_V007', 32393], ['L04_V016', 18475], ['L01_V018', 18271], ['L01_V018', 17788], ['L03_V015', 9961], ['L08_V020', 19132], ['L02_V012', 20346], ['L08_V017', 23962], ['L10_V003', 6779], ['L03_V019', 11683], ['L06_V017', 32848], ['L05_V007', 1632], ['L08_V009', 7084], ['L07_V022', 21794], ['L09_V003', 15386], ['L05_V014', 7208], ['L05_V005', 17680], ['L05_V004', 10441], ['L06_V005', 11467], ['L08_V017', 6723], ['L02_V001', 6052], ['L02_V008', 8090], ['L08_V021', 16953], ['L08_V012', 7344], ['L05_V027', 4243], ['L06_V020', 4104], ['L02_V008', 7613], ['L02_V008', 7618], ['L06_V009', 10615], ['L06_V019', 4562], ['L04_V011', 23570], ['L06_V023', 29816], ['L07_V015', 7135]]\n"
     ]
    }
   ],
   "source": [
    "query = 'The video shows a woman in a yellow shirt putting trash in a trash can. The trash can is dark green and the lid is red. The garbage that was putting in the bin said it was 1kg baby spinach.'\n",
    "\n",
    "results = predict(query, clip_embeddings, nlp, k=100)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
